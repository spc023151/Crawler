{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "import os\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 取得最大頁面"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = \"https://www.newamazing.com.tw/EW/GO/GroupList.asp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "目前可爬取最多頁面: 204\n"
     ]
    }
   ],
   "source": [
    "html = requests.get(url)\n",
    "soup = bs4.BeautifulSoup(html.text, \"lxml\")\n",
    "max_page = int(soup.find(\"input\", attrs={\"name\":\"maxPageGo\"})[\"value\"])\n",
    "print(\"目前可爬取最多頁面:\", max_page)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 可設定爬取頁面資料的其他方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "url = \"https://www.newamazing.com.tw/EW/Services/SearchListData.asp\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "page = 1  \n",
    "beginDt = \"2020/06/23\"  \n",
    "endDt = \"2021/06/23\"  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data = {\"pageAll\": page,\"beginDt\": beginDt,\"endDt\":endDt}  \n",
    "html = requests.get(url, data=data)  \n",
    "soup = bs4.BeautifulSoup(html.text, \"lxml\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 爬取行程編號並清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getGruopNumber(url, start, end=None):\n",
    "    \n",
    "    page = start\n",
    "    data = {\"pageAll\": page} # 可擴充搜尋選項\n",
    "    \n",
    "    groupNumber = []\n",
    "    \n",
    "    if(end==None):\n",
    "        html = requests.get(url, data=data)\n",
    "        soup = bs4.BeautifulSoup(html.text, \"lxml\")\n",
    "        \n",
    "        for i in soup.find_all(\"span\", \"product_num\"):\n",
    "            groupNumber.append(i.text)\n",
    "    else:\n",
    "        for i in range(start, end):\n",
    "            data[\"pageAll\"] = i\n",
    "            html = requests.get(url, data=data)\n",
    "            soup = bs4.BeautifulSoup(html.text, \"lxml\")\n",
    "        \n",
    "            for j in soup.find_all(\"span\", \"product_num\"):\n",
    "                groupNumber.append(j.text)\n",
    "                \n",
    "    return groupNumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "groupNumbers = getGruopNumber(url, 1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "360"
      ]
     },
     "execution_count": 552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(groupNumbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 爬取行程頁面"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrip(groupNumber):\n",
    "    \n",
    "    url = \"https://www.newamazing.com.tw/EW/GO/GroupDetail.asp?prodCd=\" + groupNumber\n",
    "\n",
    "    html = requests.get(url)\n",
    "    soup = bs4.BeautifulSoup(html.text, \"lxml\")\n",
    "    \n",
    "    # 標題\n",
    "    title = soup.find(\"h3\").text\n",
    "    travel_agency = soup.find(\"title\").text.replace(title+\"-\",\"\")\n",
    "    \n",
    "    # 價錢\n",
    "    price = \"\"\n",
    "    # 處理國外旅團和國內的差異\n",
    "    if(soup.find(\"li\", \"col-xs-12 col-sm-12 col-md-2 col-lg-2 price_content\")==None):\n",
    "        for i in soup.find(\"div\", \"panel-body\").find(\"span\").text:\n",
    "            if(i.isnumeric()):\n",
    "                price+=i\n",
    "    else:\n",
    "        for i in soup.find(\"li\", \"col-xs-12 col-sm-12 col-md-2 col-lg-2 price_content\").text:\n",
    "            if(i.isnumeric()):\n",
    "                price+=i\n",
    "\n",
    "    days = soup.find(\"li\", \"col-xs-12 col-sm-12 col-md-2 col-lg-2 return_date\").text.replace(\" \",\"\").replace(\"\\r\\n\",\"\")\n",
    "    \n",
    "    # 出團日期 & 天數\n",
    "    dates = []\n",
    "    remaining_number = []\n",
    "    for month in soup.find_all(\"div\", attrs={\"role\":\"tabpanel\"}):\n",
    "        for date in month.find_all(\"ul\", \"list_content\"):\n",
    "            dates.append(date.find(\"li\").text)\n",
    "            remaining_number.append(int(date.find(\"span\",\"badge\").text))\n",
    "\n",
    "    # 取出圖片網址\n",
    "    imgs = []\n",
    "    imgs_index = []\n",
    "    for img in soup.find(\"table\").find_all(\"img\"):\n",
    "        imgs.append(img[\"src\"])\n",
    "    # 下載圖片並儲存\n",
    "    for img in imgs:\n",
    "        folder_path = \"agency/NEWAMAZE/imgs\"\n",
    "        html = requests.get(img)\n",
    "\n",
    "        name = img.replace(\"https://www.newamazing.com.tw/eweb_newamazing/newfile2013/\", \"\")\n",
    "        temp = name.split(\"/\")\n",
    "\n",
    "        for i in range(len(temp)-1):\n",
    "            folder_path = folder_path + \"/\" + temp[i]\n",
    "            if (os.path.exists(folder_path) == False): #判斷資料夾是否存在\n",
    "                os.makedirs(folder_path) #Create folder\n",
    "\n",
    "        img_name = temp[-1]\n",
    "        imgs_index.append(folder_path + \"/\" + img_name)\n",
    "\n",
    "        if (img_name not in os.listdir(folder_path)):\n",
    "            with open(folder_path + \"/\" + img_name,'wb') as file: #以byte的形式將圖片數據寫入\n",
    "                file.write(html.content)\n",
    "        \n",
    "    # 航班資料\n",
    "    flights = []\n",
    "    for flight in soup.find_all(\"ul\",\"flight_content\"):\n",
    "        temp = []\n",
    "        for detail in flight.find_all(\"li\"):\n",
    "            temp.append(detail.text)\n",
    "        flights.append(temp)\n",
    "                \n",
    "    return {\"itinerary\":groupNumber,\"title\":title,\"travel_agency\":travel_agency,\"price\":price,\"days\":days,\"dates\":dates,\"remaining_number\":remaining_number,\"flights\":flights}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupNumber = groupNumbers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = getTrip(groupNumber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = dict[\"title\"]\n",
    "travel_agency = dict[\"travel_agency\"].replace(title, \"\").replace(\" \",\"\").split(\"-\")[1]\n",
    "price = dict[\"price\"]\n",
    "days = dict[\"days\"]\n",
    "dict[\"date\"] = dict[\"travel_agency\"].replace(title, \"\").replace(\" \",\"\").split(\"-\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 處理團細節\n",
    "csv_groupDetail = pd.DataFrame({\"groupNumber\":[dict[\"itinerary\"]],\"title\":[title],\"travel_agency\":[travel_agency],\"price\":[price],\"days\":[days]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 處理日期和剩多少團位\n",
    "temp = {\"dates\":dict[\"dates\"], \"remaining_number\":dict[\"remaining_number\"]}\n",
    "\n",
    "csv_groupRemaining = pd.DataFrame(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 處理班機資訊\n",
    "columns = [\"groupNumber\",\"d_day\",\"d_airlane\",\"d_number\",\"d_departure\",\"d_time\",\"d_destination\",\"d_time2\",\n",
    "           \"b_day\",\"b_airlane\",\"b_number\",\"b_departure\",\"b_time\",\"b_destination\",\"b_time2\"]\n",
    "csv_flights =  pd.DataFrame(columns=columns)\n",
    "\n",
    "if(dict[\"flights\"]==[]):\n",
    "    csv_flights = []\n",
    "else:\n",
    "    temp = {}\n",
    "    temp2 = dict[\"flights\"][0] + dict[\"flights\"][1]\n",
    "    temp2.insert(0, groupNumber)\n",
    "    for i in range(len(temp2)):\n",
    "        temp.update({columns[i]:temp2[i]})\n",
    "    csv_flights = csv_flights.append(temp,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"agency/NEWAMAZE/\"\n",
    "csv_groupDetail.to_csv(path + \"groupDetail.csv\", header=False, index=False, mode=\"a\")\n",
    "\n",
    "path = \"agency/NEWAMAZE/dateRemaining/\"\n",
    "csv_groupRemaining.to_csv(path + dict[\"itinerary\"]+\".csv\")\n",
    "\n",
    "\n",
    "if(dict[\"flights\"]==[]):\n",
    "    pass\n",
    "else:\n",
    "    path = \"agency/NEWAMAZE/\"\n",
    "    csv_flights.to_csv(path + \"flights.csv\", header=False, index=False, mode=\"a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 行程詳細介紹略過"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 大量爬蟲"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 123] 檔案名稱、目錄名稱或磁碟區標籤語法錯誤。: 'agency/NEWAMAZE/imgs/http:'\n",
      "error number:  46\n",
      "'NoneType' object has no attribute 'find_all'\n",
      "error number:  54\n",
      "'NoneType' object has no attribute 'find_all'\n",
      "error number:  83\n",
      "[WinError 123] 檔案名稱、目錄名稱或磁碟區標籤語法錯誤。: 'agency/NEWAMAZE/imgs/http:'\n",
      "error number:  131\n",
      "'NoneType' object has no attribute 'text'\n",
      "error number:  135\n",
      "'NoneType' object has no attribute 'text'\n",
      "error number:  136\n",
      "[WinError 123] 檔案名稱、目錄名稱或磁碟區標籤語法錯誤。: 'agency/NEWAMAZE/imgs/http:'\n",
      "error number:  160\n",
      "'NoneType' object has no attribute 'find_all'\n",
      "error number:  173\n",
      "'NoneType' object has no attribute 'find_all'\n",
      "error number:  175\n",
      "[WinError 123] 檔案名稱、目錄名稱或磁碟區標籤語法錯誤。: 'agency/NEWAMAZE/imgs/http:'\n",
      "error number:  208\n",
      "'NoneType' object has no attribute 'text'\n",
      "error number:  212\n",
      "'NoneType' object has no attribute 'text'\n",
      "error number:  213\n",
      "[WinError 123] 檔案名稱、目錄名稱或磁碟區標籤語法錯誤。: 'agency/NEWAMAZE/imgs/http:'\n",
      "error number:  254\n",
      "[WinError 123] 檔案名稱、目錄名稱或磁碟區標籤語法錯誤。: 'agency/NEWAMAZE/imgs/http:'\n",
      "error number:  295\n",
      "[WinError 123] 檔案名稱、目錄名稱或磁碟區標籤語法錯誤。: 'agency/NEWAMAZE/imgs/http:'\n",
      "error number:  329\n",
      "'NoneType' object has no attribute 'find_all'\n",
      "error number:  331\n",
      "'NoneType' object has no attribute 'text'\n",
      "error number:  332\n",
      "'NoneType' object has no attribute 'text'\n",
      "error number:  334\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(groupNumbers)):\n",
    "    try:\n",
    "        groupNumber = groupNumbers[i]\n",
    "        dict = getTrip(groupNumber)\n",
    "\n",
    "        title = dict[\"title\"]\n",
    "        travel_agency = dict[\"travel_agency\"].replace(title, \"\").replace(\" \",\"\").split(\"-\")[1]\n",
    "        price = dict[\"price\"]\n",
    "        days = dict[\"days\"]\n",
    "        dict[\"date\"] = dict[\"travel_agency\"].replace(title, \"\").replace(\" \",\"\").split(\"-\")[0]\n",
    "\n",
    "        # 處理團細節\n",
    "        csv_groupDetail = pd.DataFrame({\"groupNumber\":[dict[\"itinerary\"]],\"title\":[title],\"travel_agency\":[travel_agency],\"price\":[price],\"days\":[days]})\n",
    "\n",
    "        # 處理日期和剩多少團位\n",
    "        temp = {\"dates\":dict[\"dates\"], \"remaining_number\":dict[\"remaining_number\"]}\n",
    "\n",
    "        csv_groupRemaining = pd.DataFrame(temp)\n",
    "\n",
    "        # 處理班機資訊\n",
    "        columns = [\"groupNumber\",\"d_day\",\"d_airlane\",\"d_number\",\"d_departure\",\"d_time\",\"d_destination\",\"d_time2\",\n",
    "                   \"b_day\",\"b_airlane\",\"b_number\",\"b_departure\",\"b_time\",\"b_destination\",\"b_time2\"]\n",
    "        csv_flights =  pd.DataFrame(columns=columns)\n",
    "\n",
    "        if(dict[\"flights\"]==[]):\n",
    "            csv_flights = []\n",
    "        else:\n",
    "            temp = {}\n",
    "            temp2 = dict[\"flights\"][0] + dict[\"flights\"][1]\n",
    "            temp2.insert(0, groupNumber)\n",
    "            for i in range(len(temp2)):\n",
    "                temp.update({columns[i]:temp2[i]})\n",
    "            csv_flights = csv_flights.append(temp,ignore_index=True)\n",
    "\n",
    "        path = \"agency/NEWAMAZE/\"\n",
    "        csv_groupDetail.to_csv(path + \"groupDetail.csv\", header=False, index=False, mode=\"a\")\n",
    "\n",
    "        path = \"agency/NEWAMAZE/dateRemaining/\"\n",
    "        csv_groupRemaining.to_csv(path + dict[\"itinerary\"]+\".csv\")\n",
    "\n",
    "\n",
    "        if(dict[\"flights\"]==[]):\n",
    "            pass\n",
    "        else:\n",
    "            path = \"agency/NEWAMAZE/\"\n",
    "            csv_flights.to_csv(path + \"flights.csv\", header=False, index=False, mode=\"a\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"error number: \", i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
